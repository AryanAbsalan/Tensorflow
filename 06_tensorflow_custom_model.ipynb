{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for linear regression:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class CustomLinear(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "           shape = (input_shape[-1], self.units),\n",
    "           initializer = \"random_normal\",\n",
    "           trainable = True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "           shape = (self.units,), \n",
    "           initializer = \"random_normal\",\n",
    "           trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 5), dtype=float32, numpy=\n",
       "array([[ 0.04527579, -0.10158293, -0.1408679 , -0.01745914,  0.12282155],\n",
       "       [ 0.04527579, -0.10158293, -0.1408679 , -0.01745914,  0.12282155],\n",
       "       [ 0.04527579, -0.10158293, -0.1408679 , -0.01745914,  0.12282155],\n",
       "       [ 0.04527579, -0.10158293, -0.1408679 , -0.01745914,  0.12282155],\n",
       "       [ 0.04527579, -0.10158293, -0.1408679 , -0.01745914,  0.12282155],\n",
       "       [ 0.04527579, -0.10158293, -0.1408679 , -0.01745914,  0.12282155]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once the layer is defined, the instance call will automatically initialize the weights of the layer:\n",
    "\n",
    "# Definition of a CustomLinear layer with five neurons\n",
    "linear = CustomLinear(5)\n",
    "# Initialization of the weights and transformation of the data input\n",
    "data = tf.ones((6, 1))\n",
    "linear(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of weights:  2\n",
      "number of trainable weights:  2\n",
      "number of non trainable weights 0\n"
     ]
    }
   ],
   "source": [
    "print(\"number of weights: \", len(linear.weights))\n",
    "print(\"number of trainable weights: \", len(linear.trainable_weights))\n",
    "print(\"number of non trainable weights\",len(linear.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "\n",
    "class CustomPolynomial(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(CustomPolynomial, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1]*2, self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "# create a layer representing a second order polynomial regression, containing weights w and a bias b. \n",
    "# This layer will transform the inputs by applying a linear combination with the weights.\n",
    "    def call(self, inputs):\n",
    "        inputs_pow = tf.pow(inputs, 2)\n",
    "        inputs_process = tf.concat([inputs, inputs_pow], axis=-1)\n",
    "        return tf.matmul(inputs_process, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.29178956  0.09827712 -0.00870701 -0.20321968 -0.01325365  0.21515223\n",
      "  -0.05782273 -0.00833619]\n",
      " [-0.29178956  0.09827712 -0.00870701 -0.20321968 -0.01325365  0.21515223\n",
      "  -0.05782273 -0.00833619]\n",
      " [-0.29178956  0.09827712 -0.00870701 -0.20321968 -0.01325365  0.21515223\n",
      "  -0.05782273 -0.00833619]\n",
      " [-0.29178956  0.09827712 -0.00870701 -0.20321968 -0.01325365  0.21515223\n",
      "  -0.05782273 -0.00833619]], shape=(4, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "customlayer = CustomPolynomial(8)\n",
    "\n",
    "# Definition of an input vector\n",
    "inputs = tf.ones((4, 5))\n",
    "\n",
    "# Apply the custom layer operation.\n",
    "output = customlayer(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of weights:  2\n",
      "number of trainable weights:  2\n",
      "number of non trainable weights 0\n"
     ]
    }
   ],
   "source": [
    "print(\"number of weights: \", len(customlayer.weights))\n",
    "print(\"number of trainable weights: \", len(customlayer.trainable_weights))\n",
    "print(\"number of non trainable weights\",len(customlayer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(Layer):\n",
    "    def __init__(self, rate):\n",
    "        super(CustomDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom model inherited from the Model class.\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Softmax\n",
    "\n",
    "class CustomModel(Model):\n",
    "    def __init__(self, units_1, units_2, n_classes):\n",
    "        # Initialization of the Model class.\n",
    "        super(CustomModel, self).__init__()\n",
    "        # Definition of each layer of our model.\n",
    "        self.linear_1 = CustomLinear(units_1)\n",
    "        self.dropout_1 = CustomDropout(rate=0.2)\n",
    "\n",
    "        self.linear_2 = CustomLinear(units_2)\n",
    "        self.dropout_2 = CustomDropout(rate=0.2)\n",
    "\n",
    "        self.linear_3 = CustomLinear(n_classes)\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply the operation of each layer.\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "\n",
    "        x = self.linear_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "\n",
    "        x = self.linear_3(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU, Softmax\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(CustomPolynomial(32))\n",
    "model.add(CustomDropout(0.2))\n",
    "model.add(ReLU())\n",
    "\n",
    "model.add(CustomPolynomial(64))\n",
    "model.add(CustomDropout(0.2))\n",
    "model.add(ReLU())\n",
    "\n",
    "model.add(CustomPolynomial(1))\n",
    "model.add(ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.00670942],\n",
       "       [0.00670942],\n",
       "       [0.00670942],\n",
       "       [0.00670942],\n",
       "       [0.00670942],\n",
       "       [0.00670942],\n",
       "       [0.00670942],\n",
       "       [0.00670942],\n",
       "       [0.00670942],\n",
       "       [0.00670942]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.ones([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>PressureLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020584</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>0.832443</td>\n",
       "      <td>0.212339</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183405</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.524756</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>0.291229</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611853</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>0.292145</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>0.456070</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  PressureLevel\n",
       "0   0.374540   0.950714   0.731994   0.598658   0.156019             50\n",
       "1   0.155995   0.058084   0.866176   0.601115   0.708073             70\n",
       "2   0.020584   0.969910   0.832443   0.212339   0.181825             95\n",
       "3   0.183405   0.304242   0.524756   0.431945   0.291229             47\n",
       "4   0.611853   0.139494   0.292145   0.366362   0.456070             18"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a dataset with 1000 samples and 5 feature columns\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "\n",
    "# Generate random feature data (values between 0 and 1)\n",
    "features_data = np.random.rand(n_samples, n_features)\n",
    "\n",
    "# Generate random target data (PressureLevel) - using values between 0 and 100\n",
    "target_data = np.random.randint(0, 100, size=n_samples)\n",
    "\n",
    "# Convert to a DataFrame for features and a Series for the target\n",
    "columns = [f'feature_{i}' for i in range(1, n_features+1)]\n",
    "df = pd.DataFrame(features_data, columns=columns)\n",
    "df['PressureLevel'] = target_data\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 5)\n",
      "X_test shape: (200, 5)\n",
      "y_train shape: (800,)\n",
      "y_test shape: (200,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into features and target\n",
    "features = df.drop(['PressureLevel'], axis=1)\n",
    "target = df['PressureLevel']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_3612\\3483093910.py:5: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  y_train = y_train.ravel().reshape(-1, 1)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_3612\\3483093910.py:6: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  y_test = y_test.ravel().reshape(-1, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "y_train = y_train.ravel().reshape(-1, 1)\n",
    "y_test = y_test.ravel().reshape(-1, 1)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# Features\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "# Target\n",
    "y_train = y_scaler.transform(y_train)\n",
    "y_test = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0314 - mean_absolute_error: 0.8816 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9470 - mean_absolute_error: 0.8275 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0301 - mean_absolute_error: 0.8730 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9621 - mean_absolute_error: 0.8466 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0084 - mean_absolute_error: 0.8605 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0553 - mean_absolute_error: 0.8908 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9814 - mean_absolute_error: 0.8476 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0244 - mean_absolute_error: 0.8743 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9867 - mean_absolute_error: 0.8533 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0028 - mean_absolute_error: 0.8616 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0378 - mean_absolute_error: 0.8779 - val_loss: 0.9687 - val_mean_absolute_error: 0.8699\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9950 - mean_absolute_error: 0.8589 - val_loss: 0.9687 - val_mean_absolute_error: 0.8700\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0113 - mean_absolute_error: 0.8629 - val_loss: 0.9734 - val_mean_absolute_error: 0.8714\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0818 - mean_absolute_error: 0.9032 - val_loss: 0.9742 - val_mean_absolute_error: 0.8714\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0261 - mean_absolute_error: 0.8731 - val_loss: 0.9748 - val_mean_absolute_error: 0.8698\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0047 - mean_absolute_error: 0.8614 - val_loss: 0.9746 - val_mean_absolute_error: 0.8701\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9889 - mean_absolute_error: 0.8522 - val_loss: 0.9816 - val_mean_absolute_error: 0.8708\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0034 - mean_absolute_error: 0.8637 - val_loss: 0.9711 - val_mean_absolute_error: 0.8681\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0317 - mean_absolute_error: 0.8735 - val_loss: 0.9794 - val_mean_absolute_error: 0.8693\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9826 - mean_absolute_error: 0.8535 - val_loss: 0.9802 - val_mean_absolute_error: 0.8698\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9824 - mean_absolute_error: 0.8443 - val_loss: 0.9813 - val_mean_absolute_error: 0.8699\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0503 - mean_absolute_error: 0.9007 - val_loss: 0.9853 - val_mean_absolute_error: 0.8707\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9950 - mean_absolute_error: 0.8455 - val_loss: 0.9885 - val_mean_absolute_error: 0.8708\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9654 - mean_absolute_error: 0.8397 - val_loss: 0.9916 - val_mean_absolute_error: 0.8710\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9697 - mean_absolute_error: 0.8424 - val_loss: 0.9808 - val_mean_absolute_error: 0.8692\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9077 - mean_absolute_error: 0.8174 - val_loss: 0.9977 - val_mean_absolute_error: 0.8717\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0117 - mean_absolute_error: 0.8593 - val_loss: 1.0019 - val_mean_absolute_error: 0.8723\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9919 - mean_absolute_error: 0.8546 - val_loss: 0.9944 - val_mean_absolute_error: 0.8702\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9807 - mean_absolute_error: 0.8473 - val_loss: 0.9902 - val_mean_absolute_error: 0.8693\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9529 - mean_absolute_error: 0.8352 - val_loss: 0.9883 - val_mean_absolute_error: 0.8684\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9323 - mean_absolute_error: 0.8193 - val_loss: 0.9781 - val_mean_absolute_error: 0.8664\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8632 - mean_absolute_error: 0.7883 - val_loss: 0.9874 - val_mean_absolute_error: 0.8667\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9763 - mean_absolute_error: 0.8451 - val_loss: 0.9867 - val_mean_absolute_error: 0.8689\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9827 - mean_absolute_error: 0.8472 - val_loss: 1.0125 - val_mean_absolute_error: 0.8740\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9622 - mean_absolute_error: 0.8377 - val_loss: 0.9910 - val_mean_absolute_error: 0.8685\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9530 - mean_absolute_error: 0.8297 - val_loss: 0.9977 - val_mean_absolute_error: 0.8701\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9122 - mean_absolute_error: 0.8054 - val_loss: 1.0038 - val_mean_absolute_error: 0.8701\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9906 - mean_absolute_error: 0.8493 - val_loss: 0.9940 - val_mean_absolute_error: 0.8682\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9412 - mean_absolute_error: 0.8363 - val_loss: 0.9953 - val_mean_absolute_error: 0.8687\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9536 - mean_absolute_error: 0.8267 - val_loss: 1.0033 - val_mean_absolute_error: 0.8697\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9389 - mean_absolute_error: 0.8242 - val_loss: 0.9905 - val_mean_absolute_error: 0.8679\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9510 - mean_absolute_error: 0.8344 - val_loss: 0.9885 - val_mean_absolute_error: 0.8667\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9482 - mean_absolute_error: 0.8286 - val_loss: 0.9970 - val_mean_absolute_error: 0.8689\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9125 - mean_absolute_error: 0.8097 - val_loss: 1.0019 - val_mean_absolute_error: 0.8686\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9345 - mean_absolute_error: 0.8203 - val_loss: 0.9945 - val_mean_absolute_error: 0.8676\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9305 - mean_absolute_error: 0.8149 - val_loss: 1.0189 - val_mean_absolute_error: 0.8729\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9537 - mean_absolute_error: 0.8270 - val_loss: 0.9924 - val_mean_absolute_error: 0.8704\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9202 - mean_absolute_error: 0.8187 - val_loss: 1.0042 - val_mean_absolute_error: 0.8703\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9276 - mean_absolute_error: 0.8148 - val_loss: 0.9945 - val_mean_absolute_error: 0.8687\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9200 - mean_absolute_error: 0.8103 - val_loss: 1.0167 - val_mean_absolute_error: 0.8728\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9270 - mean_absolute_error: 0.8180 - val_loss: 1.0105 - val_mean_absolute_error: 0.8736\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9537 - mean_absolute_error: 0.8391 - val_loss: 0.9930 - val_mean_absolute_error: 0.8701\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9145 - mean_absolute_error: 0.8095 - val_loss: 1.0149 - val_mean_absolute_error: 0.8747\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9563 - mean_absolute_error: 0.8313 - val_loss: 0.9966 - val_mean_absolute_error: 0.8715\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9329 - mean_absolute_error: 0.8220 - val_loss: 1.0118 - val_mean_absolute_error: 0.8719\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9653 - mean_absolute_error: 0.8408 - val_loss: 0.9976 - val_mean_absolute_error: 0.8703\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9244 - mean_absolute_error: 0.8172 - val_loss: 1.0094 - val_mean_absolute_error: 0.8726\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8919 - mean_absolute_error: 0.8052 - val_loss: 1.0041 - val_mean_absolute_error: 0.8714\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9096 - mean_absolute_error: 0.8059 - val_loss: 0.9959 - val_mean_absolute_error: 0.8699\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9340 - mean_absolute_error: 0.8166 - val_loss: 1.0038 - val_mean_absolute_error: 0.8700\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9153 - mean_absolute_error: 0.8062 - val_loss: 1.0089 - val_mean_absolute_error: 0.8703\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9288 - mean_absolute_error: 0.8076 - val_loss: 1.0071 - val_mean_absolute_error: 0.8721\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9535 - mean_absolute_error: 0.8343 - val_loss: 0.9966 - val_mean_absolute_error: 0.8702\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9149 - mean_absolute_error: 0.8104 - val_loss: 1.0005 - val_mean_absolute_error: 0.8720\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9377 - mean_absolute_error: 0.8260 - val_loss: 1.0155 - val_mean_absolute_error: 0.8711\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9268 - mean_absolute_error: 0.8189 - val_loss: 1.0013 - val_mean_absolute_error: 0.8747\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8889 - mean_absolute_error: 0.7940 - val_loss: 1.0167 - val_mean_absolute_error: 0.8776\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9274 - mean_absolute_error: 0.8092 - val_loss: 1.0153 - val_mean_absolute_error: 0.8756\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8928 - mean_absolute_error: 0.7807 - val_loss: 1.0048 - val_mean_absolute_error: 0.8742\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8709 - mean_absolute_error: 0.7843 - val_loss: 1.0256 - val_mean_absolute_error: 0.8762\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9018 - mean_absolute_error: 0.7954 - val_loss: 1.0201 - val_mean_absolute_error: 0.8757\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8890 - mean_absolute_error: 0.7802 - val_loss: 1.0052 - val_mean_absolute_error: 0.8757\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9052 - mean_absolute_error: 0.8017 - val_loss: 1.0211 - val_mean_absolute_error: 0.8782\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9134 - mean_absolute_error: 0.8009 - val_loss: 1.0500 - val_mean_absolute_error: 0.8858\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9251 - mean_absolute_error: 0.8078 - val_loss: 1.0199 - val_mean_absolute_error: 0.8790\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8795 - mean_absolute_error: 0.7919 - val_loss: 1.0311 - val_mean_absolute_error: 0.8796\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9045 - mean_absolute_error: 0.8113 - val_loss: 1.0403 - val_mean_absolute_error: 0.8838\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9249 - mean_absolute_error: 0.8193 - val_loss: 1.0168 - val_mean_absolute_error: 0.8783\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8796 - mean_absolute_error: 0.7815 - val_loss: 1.0319 - val_mean_absolute_error: 0.8822\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8947 - mean_absolute_error: 0.7963 - val_loss: 1.0255 - val_mean_absolute_error: 0.8819\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9794 - mean_absolute_error: 0.8462 - val_loss: 1.0483 - val_mean_absolute_error: 0.8892\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8716 - mean_absolute_error: 0.7823 - val_loss: 1.0224 - val_mean_absolute_error: 0.8835\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9292 - mean_absolute_error: 0.8213 - val_loss: 1.0469 - val_mean_absolute_error: 0.8834\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8960 - mean_absolute_error: 0.7912 - val_loss: 1.0272 - val_mean_absolute_error: 0.8807\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8914 - mean_absolute_error: 0.7936 - val_loss: 1.0593 - val_mean_absolute_error: 0.8910\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9072 - mean_absolute_error: 0.8054 - val_loss: 1.0420 - val_mean_absolute_error: 0.8853\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8700 - mean_absolute_error: 0.7882 - val_loss: 1.0328 - val_mean_absolute_error: 0.8826\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8685 - mean_absolute_error: 0.7914 - val_loss: 1.0396 - val_mean_absolute_error: 0.8845\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9235 - mean_absolute_error: 0.8074 - val_loss: 1.0470 - val_mean_absolute_error: 0.8884\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8787 - mean_absolute_error: 0.7863 - val_loss: 1.0666 - val_mean_absolute_error: 0.8948\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8853 - mean_absolute_error: 0.7852 - val_loss: 1.0285 - val_mean_absolute_error: 0.8819\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8950 - mean_absolute_error: 0.7985 - val_loss: 1.0565 - val_mean_absolute_error: 0.8916\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9298 - mean_absolute_error: 0.8153 - val_loss: 1.0518 - val_mean_absolute_error: 0.8908\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8263 - mean_absolute_error: 0.7527 - val_loss: 1.0796 - val_mean_absolute_error: 0.9002\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8757 - mean_absolute_error: 0.7859 - val_loss: 1.0351 - val_mean_absolute_error: 0.8858\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8887 - mean_absolute_error: 0.7907 - val_loss: 1.0517 - val_mean_absolute_error: 0.8913\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9077 - mean_absolute_error: 0.8001 - val_loss: 1.0555 - val_mean_absolute_error: 0.8920\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8743 - mean_absolute_error: 0.7768 - val_loss: 1.0491 - val_mean_absolute_error: 0.8895\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9263 - mean_absolute_error: 0.8130 - val_loss: 1.0608 - val_mean_absolute_error: 0.8935\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8645 - mean_absolute_error: 0.7838 - val_loss: 1.0707 - val_mean_absolute_error: 0.8978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32,\n",
    "                    epochs=100, \n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
